{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\n",
      "torch.Size([512, 180])\n",
      "[66]\n",
      "torch.Size([512, 198])\n"
     ]
    }
   ],
   "source": [
    "file = \"/ssd_scratch/cvit/kolubex/data/audio_feats/total/finetuned_t_25/tt0037884/scene-065.ss-0220.es-0223.pkl\"\n",
    "with open(file, 'rb') as f:\n",
    "    masks = pkl.load(f)\n",
    "    feats = pkl.load(f)\n",
    "print(masks)\n",
    "print(feats.shape)\n",
    "file1 = \"/ssd_scratch/cvit/kolubex/data/audio_feats/total/finetuned_t_25/tt0037884/scene-046.ss-0154.es-0159.pkl\"\n",
    "with open(file1, 'rb') as f:\n",
    "    masks = pkl.load(f)\n",
    "    feats = pkl.load(f)\n",
    "print(masks)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files unique to Folder 1:\n",
      "set()\n",
      "\n",
      "Files unique to Folder 2:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(directory):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_list.append(os.path.relpath(os.path.join(root, file), directory))\n",
    "    return file_list\n",
    "\n",
    "def compare_folders(folder1, folder2):\n",
    "    files1 = set(list_files(folder1))\n",
    "    files2 = set(list_files(folder2))\n",
    "\n",
    "    common_files = files1.intersection(files2)\n",
    "    unique_files_folder1 = files1 - common_files\n",
    "    unique_files_folder2 = files2 - common_files\n",
    "\n",
    "    return {\n",
    "        'common_files': common_files,\n",
    "        'unique_files_folder1': unique_files_folder1,\n",
    "        'unique_files_folder2': unique_files_folder2\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "folder1_path = '/ssd_scratch/cvit/kolubex/data/audios/vocals'\n",
    "folder2_path = '/ssd_scratch/cvit/kolubex/data/audios/total'\n",
    "\n",
    "differences = compare_folders(folder1_path, folder2_path)\n",
    "\n",
    "\n",
    "print(\"\\nFiles unique to Folder 1:\")\n",
    "print(differences['unique_files_folder1'])\n",
    "\n",
    "print(\"\\nFiles unique to Folder 2:\")\n",
    "print(differences['unique_files_folder2'])\n",
    "\n",
    "# copy files from folder2 to folder1\n",
    "# import shutil\n",
    "# for file in differences['unique_files_folder2']:\n",
    "#     shutil.copy(os.path.join(folder2_path, file), os.path.join(folder1_path, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks: [82]\n",
      "audio_feats.shape torch.Size([240, 512])\n",
      "times.shape torch.Size([245])\n",
      "audio_feats.shape torch.Size([298, 512])\n",
      "scene: 1\n",
      "times.shape torch.Size([300])\n",
      "audio_pad_mask.shape torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "scenes = [1]\n",
    "import pickle\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "audio_pad_mask = torch.zeros(300,)\n",
    "audio_feats = torch.empty((0, 512))\n",
    "times = torch.empty(0,)\n",
    "for scene in scenes:\n",
    "            with open(\"/ssd_scratch/cvit/kolubex/data/audio_feats/vocals/finetuned_t_25/tt0212338/scene-140.ss-1429.es-1454.pkl\", 'rb') as f:\n",
    "                masks = pickle.load(f)\n",
    "                feats = pickle.load(f)\n",
    "                print(f\"masks: {masks}\")\n",
    "                feats = feats.transpose(0, 1)\n",
    "                time = numpy.arange(1,masks[0]*3) * 1/3\n",
    "                time = time - 0.01\n",
    "\n",
    "            if len(feats):\n",
    "                audio_feats = torch.cat([audio_feats, feats], dim=0)\n",
    "                times = torch.cat([times, torch.from_numpy(time)], dim=0)\n",
    "audio_feats = audio_feats[:300, :]\n",
    "print(\"audio_feats.shape\", audio_feats.shape)\n",
    "print(\"times.shape\", times.shape)\n",
    "times = times[:int(300)]\n",
    "audio_feats = audio_feats[:int(300), :]\n",
    "# print(\"times.shape\", times.shape)\n",
    "# print(\"audio_feats.shape_before\", audio_feats.shape)\n",
    "audio_pad_mask[(times.shape[0]):] = 1\n",
    "pad_len = int(300 - (times.shape[0]))\n",
    "times = torch.cat([times, torch.zeros(pad_len,)])\n",
    "# print(\"audio_feats.shape_before_pad\", audio_feats.shape)\n",
    "audio_feats = torch.cat([audio_feats, torch.zeros(((pad_len+3), 512))])\n",
    "audio_feats = audio_feats[:300, :]\n",
    "print(\"audio_feats.shape\", audio_feats.shape)\n",
    "if(audio_feats.shape[0] != 300):\n",
    "    print(f\"scene: {scene}\")\n",
    "print(\"times.shape\", times.shape)\n",
    "print(\"audio_pad_mask.shape\", audio_pad_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats.shape: torch.Size([86, 512])\n",
      "masks: [35]\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import pickle\n",
    "with open(\"/ssd_scratch/cvit/kolubex/data/audio_feats/vocals/finetuned_t_25/tt0167404/scene-003.ss-0012.es-0017.pkl\", 'rb') as f:\n",
    "    masks = pickle.load(f)\n",
    "    feats = pickle.load(f)\n",
    "    feats = feats.transpose(0, 1)\n",
    "    print(f\"feats.shape: {feats.shape}\")\n",
    "    print(f\"masks: {masks}\")\n",
    "    time = numpy.arange(1,masks[0]*3) * 1/3\n",
    "    time = time - 0.01\n",
    "    print(time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
